# SIH25081 MVP - Kochi Metro Train Scheduling Optimizer

This repository contains a full working MVP for the **Smart AI-driven Train Scheduling System** described in SIH Problem Statement **SIH25081**. 

The goal is to provide Kochi Metro Rail Limited with a **decision-support system** that automates nightly scheduling of trainsets while considering multiple constraints (fitness certificates, job-card status, branding priorities, mileage balancing, cleaning slots, and stabling geometry).

---

## ğŸ“œ Problem Statement (Simplified)
KMRL must decide each night:
- Which trains run in the morning service.
- Which trains remain standby.
- Which trains are taken for maintenance or cleaning.

Currently, this is done manually using spreadsheets and WhatsApp logs, leading to errors, inefficiency, and scalability issues.  
The MVP demonstrates how an AI + optimization-driven system can automate this decision-making with explainability and simulation.

---

## ğŸ› ï¸ Tech Stack

### **Frontend**
- HTML/CSS/JS (basic MVP UI in `static/index.html`)
- Axios-style fetch calls for backend API
- Tailwind/React can be added later

### **Backend**
- **FastAPI** â†’ REST API for scheduling & data
- **Python PuLP** â†’ Linear optimization & constraint solver (CBC backend)
- **Pandas** â†’ Data handling (CSV datasets)
- **Uvicorn** â†’ ASGI server

### **Machine Learning (Stretch Features)**
- **Scikit-learn** â†’ Baseline classification model
- **TensorFlow/Keras** â†’ Deep neural network (predictive maintenance)
- **NumPy/Pandas** â†’ preprocessing

### **Database/Storage**
- CSV datasets (synthetic mock data in `data/`)
- PostgreSQL/MongoDB can replace later for persistence

### **DevOps / Cloud**
- Dockerfile included â†’ containerize backend
- Google Cloud / DigitalOcean / Vercel for deployment

### **Collaboration**
- GitHub for version control
- Figma/Canva for design
- Trello/Notion for task management

### **Testing**
- PyTest for backend logic
- Jest/Cypress can be added for frontend

---

## ğŸ“‚ Project Structure

```
sih25081_mvp/
â”‚â”€â”€ backend_main.py       # FastAPI + PuLP backend
â”‚â”€â”€ requirements.txt      # Dependencies
â”‚â”€â”€ README.md             # Project details
â”‚â”€â”€ Dockerfile            # Container build file
â”‚â”€â”€ run.sh                # Helper script
â”‚â”€â”€ data/                 # Synthetic CSV datasets
â”‚    â”œâ”€â”€ trains.csv
â”‚    â”œâ”€â”€ fitness.csv
â”‚    â”œâ”€â”€ jobcard.csv
â”‚    â”œâ”€â”€ branding.csv
â”‚    â”œâ”€â”€ mileage.csv
â”‚    â”œâ”€â”€ cleaning.csv
â”‚    â””â”€â”€ stabling.csv
â”‚â”€â”€ static/               # Frontend UI
â”‚    â””â”€â”€ index.html
```

---

## ğŸ“Š Features in MVP

âœ… Ingests synthetic datasets for 1000 trains  
âœ… Applies constraints (fitness expiry, job-card, branding, cleaning capacity)  
âœ… Balances mileage across trains  
âœ… Generates daily schedule (Run / Standby / Cleaning / Maintenance)  
âœ… Provides reasoning per train (why it was assigned)  
âœ… Offers **what-if simulation** (simulate a train failure, adjust cleaning slots)  
âœ… Frontend UI to view schedules and rerun optimizer  

â¡ï¸ New: Photo ingestion (WhatsApp/logbook) with Groq vision LLM. See [INGESTION.md](./INGESTION.md).

---

## ğŸ”¥ Stretch Features

- Classification model for predictive maintenance (risk score for failures)  
- Deep Neural Network for advanced reliability predictions  
- Integration with cloud deployment  
- Richer frontend with charts and dashboards (React/Next.js)  
- Database integration for real-time data ingestion  

---

## ğŸ“… Roadmap

- **Week 1:** Build rule-based PuLP optimizer with mock data  
- **Week 2:** Expose APIs with FastAPI and add frontend visualization  
- **Week 3:** Add simulation features + integrate ML model  
- **Week 4:** Polish UI, prepare pitch and presentation for SIH  

---

## ğŸ“ Detailed Prompt to Recreate MVP

If you need to regenerate this MVP from scratch, use this prompt:

```
Create a full MVP for SIH25081 (AI-driven Train Scheduling for Kochi Metro) with:
- Backend: Python (FastAPI), PuLP for optimization, Pandas for data handling.
- Endpoints: `/api/data` (fetch CSVs), `/api/schedule` (run optimizer, return JSON).
- Constraints: 
  - Fitness expired â†’ cannot run
  - Job card open â†’ must rest
  - Branding priority â†’ must run (add bonus in objective)
  - Cleaning slot capacity (limit trains in cleaning)
  - Mileage balancing â†’ minimize variance
  - What-if simulation: fail_train param forces maintenance
- Objective: Weighted sum of (risk + mileage deviation - branding bonus).
- Datasets: 6 CSVs (trains, fitness, jobcard, branding, mileage, cleaning, stabling).
- Frontend: Minimal HTML/JS page with controls for cleaning capacity and failure simulation, table to display results.
- Deliverables: backend_main.py, requirements.txt, datasets, static/index.html, Dockerfile, README.md.
```